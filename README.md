Audio Classification – Project README
Project Summary

This project develops a deep learning classifier for recognizing three animal sounds: dog, cat, and bird. The baseline model uses 2D CNNs trained on Mel-spectrograms, and a second model will apply transfer learning using pretrained audio models such as YAMNet or VGGish. The goal is to compare traditional CNN learning with transfer-learning-based audio embeddings.

Team Members & GitHub Usernames

Shambhavi Adhikari (G37903602) — your-github-username

Rakshitha Mamilla (G23922354) — their-github-username

Abhiyan Sainju (G22510509) — their-github-username

Dataset Source

Human Words Audio Classification (Kaggle)
Dataset link:
https://www.kaggle.com/datasets/chiragchhaya/human-words-audio-classification

Initial Work

Dataset downloaded and examined.

Mel-spectrogram generation tested.

Initial notebook/Python file created to begin preprocessing and baseline CNN setup.

Future Work

CNN-based audio classification pipeline built on Mel-spectrograms.

Include a minimal baseline model and data/EDA checklist.

Add an optional Phase-2 using pretrained audio embeddings (YAMNet/VGGish).

Report results using Accuracy, Macro-F1, and a confusion matrix.
