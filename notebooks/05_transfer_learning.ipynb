{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e751a9f4",
   "metadata": {},
   "source": [
    "# 05 – Transfer Learning with YAMNet Embeddings\n",
    "\n",
    "**Course:** CSCI 6366 (Neural Networks and Deep Learning)  \n",
    "**Project:** Audio Classification using CNN  \n",
    "**Notebook:** Transfer Learning with Pre-trained Audio Embeddings (YAMNet)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we extend our previous experiments (02–04) by using\n",
    "**transfer learning** with a pre-trained audio model, **YAMNet**, to classify\n",
    "animal sounds (`dog`, `cat`, `bird`).\n",
    "\n",
    "Instead of training a CNN from scratch on Mel-spectrograms, we:\n",
    "\n",
    "1. Use a pre-trained YAMNet model (trained on AudioSet) to extract\n",
    "   high-level audio **embeddings** from each waveform.\n",
    "\n",
    "2. Train a small neural network (Dense layers) **on top of these embeddings**\n",
    "   to classify our three animal classes.\n",
    "\n",
    "3. Compare this transfer-learning approach to our best CNN from\n",
    "   `04_cnn_full_data.ipynb` (CNN + Dropout 0.3).\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "- Reuse the same dataset and class labels as before.\n",
    "- Keep a similar **train/validation/test split** (stratified, random_state=42).\n",
    "- Evaluate test accuracy, confusion matrix, and per-class metrics.\n",
    "- Discuss how transfer learning compares to our custom CNN models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43a5a3",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "We import TensorFlow, TensorFlow Hub (for YAMNet), librosa, NumPy, and sklearn; and set constants similar to notebook 04.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c720ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Paths and constants\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "SAMPLE_RATE = 16000  # YAMNet expects 16 kHz audio\n",
    "\n",
    "CLASS_NAMES = [\"dog\", \"cat\", \"bird\"]\n",
    "label_to_index = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n",
    "\n",
    "# Train/val/test ratios (match notebook 04)\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15  # of the remaining after test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95afc055",
   "metadata": {},
   "source": [
    "## 2. Dataset: File Paths and Labels\n",
    "\n",
    "We reuse the same `data/` directory structure:\n",
    "\n",
    "- `data/dog/*.wav`\n",
    "- `data/cat/*.wav`\n",
    "- `data/bird/*.wav`\n",
    "\n",
    "Here we collect:\n",
    "\n",
    "- `file_paths`: list of `Path` objects to WAV files\n",
    "- `labels`: integer label indices (`0 = dog`, `1 = cat`, `2 = bird`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_file_paths_and_labels(data_dir: Path):\n",
    "    \"\"\"Collect all .wav file paths and integer labels.\"\"\"\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in CLASS_NAMES:\n",
    "        class_dir = data_dir / label\n",
    "        wav_files = sorted(class_dir.glob(\"*.wav\"))\n",
    "        \n",
    "        for audio_path in wav_files:\n",
    "            file_paths.append(audio_path)\n",
    "            labels.append(label_to_index[label])\n",
    "    \n",
    "    return np.array(file_paths), np.array(labels, dtype=np.int32)\n",
    "\n",
    "file_paths, labels = collect_file_paths_and_labels(DATA_DIR)\n",
    "print(\"Total files:\", len(file_paths))\n",
    "for idx, label_name in enumerate(CLASS_NAMES):\n",
    "    count = np.sum(labels == idx)\n",
    "    print(f\"{label_name}: {count} files\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
