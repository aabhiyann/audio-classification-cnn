{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e751a9f4",
   "metadata": {},
   "source": [
    "# 05 – Transfer Learning with YAMNet Embeddings\n",
    "\n",
    "**Course:** CSCI 6366 (Neural Networks and Deep Learning)  \n",
    "**Project:** Audio Classification using CNN  \n",
    "**Notebook:** Transfer Learning with Pre-trained Audio Embeddings (YAMNet)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we extend our previous experiments (02–04) by using\n",
    "**transfer learning** with a pre-trained audio model, **YAMNet**, to classify\n",
    "animal sounds (`dog`, `cat`, `bird`).\n",
    "\n",
    "Instead of training a CNN from scratch on Mel-spectrograms, we:\n",
    "\n",
    "1. Use a pre-trained YAMNet model (trained on AudioSet) to extract\n",
    "   high-level audio **embeddings** from each waveform.\n",
    "\n",
    "2. Train a small neural network (Dense layers) **on top of these embeddings**\n",
    "   to classify our three animal classes.\n",
    "\n",
    "3. Compare this transfer-learning approach to our best CNN from\n",
    "   `04_cnn_full_data.ipynb` (CNN + Dropout 0.3).\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "- Reuse the same dataset and class labels as before.\n",
    "- Keep a similar **train/validation/test split** (stratified, random_state=42).\n",
    "- Evaluate test accuracy, confusion matrix, and per-class metrics.\n",
    "- Discuss how transfer learning compares to our custom CNN models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43a5a3",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "We import TensorFlow, TensorFlow Hub (for YAMNet), librosa, NumPy, and sklearn; and set constants similar to notebook 04.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c720ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Paths and constants\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "SAMPLE_RATE = 16000  # YAMNet expects 16 kHz audio\n",
    "\n",
    "CLASS_NAMES = [\"dog\", \"cat\", \"bird\"]\n",
    "label_to_index = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n",
    "\n",
    "# Train/val/test ratios (match notebook 04)\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15  # of the remaining after test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95afc055",
   "metadata": {},
   "source": [
    "## 2. Dataset: File Paths and Labels\n",
    "\n",
    "We reuse the same `data/` directory structure:\n",
    "\n",
    "- `data/dog/*.wav`\n",
    "- `data/cat/*.wav`\n",
    "- `data/bird/*.wav`\n",
    "\n",
    "Here we collect:\n",
    "\n",
    "- `file_paths`: list of `Path` objects to WAV files\n",
    "- `labels`: integer label indices (`0 = dog`, `1 = cat`, `2 = bird`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c42861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 610\n",
      "dog: 210 files\n",
      "cat: 207 files\n",
      "bird: 193 files\n"
     ]
    }
   ],
   "source": [
    "def collect_file_paths_and_labels(data_dir: Path):\n",
    "    \"\"\"Collect all .wav file paths and integer labels.\"\"\"\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in CLASS_NAMES:\n",
    "        class_dir = data_dir / label\n",
    "        wav_files = sorted(class_dir.glob(\"*.wav\"))\n",
    "        \n",
    "        for audio_path in wav_files:\n",
    "            file_paths.append(audio_path)\n",
    "            labels.append(label_to_index[label])\n",
    "    \n",
    "    return np.array(file_paths), np.array(labels, dtype=np.int32)\n",
    "\n",
    "file_paths, labels = collect_file_paths_and_labels(DATA_DIR)\n",
    "print(\"Total files:\", len(file_paths))\n",
    "for idx, label_name in enumerate(CLASS_NAMES):\n",
    "    count = np.sum(labels == idx)\n",
    "    print(f\"{label_name}: {count} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afd4fae",
   "metadata": {},
   "source": [
    "## 3. Stratified Train / Validation / Test Split\n",
    "\n",
    "We create explicit train, validation, and test sets using stratified splits.\n",
    "We use the **same ratios and random_state=42** as in `04_cnn_full_data.ipynb` so\n",
    "the splits are comparable:\n",
    "\n",
    "- Test set: 15% of data\n",
    "- From the remaining 85%, we take 15% as validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3334bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 440\n",
      "Validation size: 78\n",
      "Test size: 92\n",
      "\n",
      "Train distribution:\n",
      "  dog: 151\n",
      "  cat: 150\n",
      "  bird: 139\n",
      "\n",
      "Validation distribution:\n",
      "  dog: 27\n",
      "  cat: 26\n",
      "  bird: 25\n",
      "\n",
      "Test distribution:\n",
      "  dog: 32\n",
      "  cat: 31\n",
      "  bird: 29\n"
     ]
    }
   ],
   "source": [
    "# First split off test set\n",
    "paths_train_full, paths_test, y_train_full, y_test = train_test_split(\n",
    "    file_paths,\n",
    "    labels,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=42,\n",
    "    stratify=labels,\n",
    ")\n",
    "\n",
    "# Now split train_full into train and validation\n",
    "paths_train, paths_val, y_train, y_val = train_test_split(\n",
    "    paths_train_full,\n",
    "    y_train_full,\n",
    "    test_size=VAL_SIZE,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(paths_train))\n",
    "print(\"Validation size:\", len(paths_val))\n",
    "print(\"Test size:\", len(paths_test))\n",
    "\n",
    "def print_split_stats(name, y_split):\n",
    "    print(f\"\\n{name} distribution:\")\n",
    "    for idx, label_name in enumerate(CLASS_NAMES):\n",
    "        count = np.sum(y_split == idx)\n",
    "        print(f\"  {label_name}: {count}\")\n",
    "\n",
    "print_split_stats(\"Train\", y_train)\n",
    "print_split_stats(\"Validation\", y_val)\n",
    "print_split_stats(\"Test\", y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db4af7",
   "metadata": {},
   "source": [
    "## 4. YAMNet: Pre-trained Audio Model\n",
    "\n",
    "We use **YAMNet**, a convolutional neural network trained on Google's\n",
    "AudioSet dataset. It takes a 16 kHz mono waveform and outputs:\n",
    "\n",
    "- Class scores (for many audio event classes),\n",
    "- Intermediate **embeddings** (1024-dimensional vectors),\n",
    "- Log Mel-spectrogram (internal representation).\n",
    "\n",
    "For transfer learning, we will:\n",
    "\n",
    "1. Load each audio file at 16 kHz (mono).\n",
    "2. Pass the waveform through YAMNet.\n",
    "3. Take the **average** of all frame-level embeddings to get a single\n",
    "   1024-D embedding vector per clip.\n",
    "4. Use these embeddings as input features to a small classifier network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad957f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YAMNet from TensorFlow Hub...\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1348\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1286\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1285\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1332\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1331\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1332\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1281\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1280\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1281\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1041\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1044\u001b[39m \n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:979\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1458\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1456\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:517\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    512\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    513\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    514\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    515\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1075\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1074\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1346\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1345\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1346\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m YAMNET_HANDLE = \u001b[33m\"\u001b[39m\u001b[33mhttps://tfhub.dev/google/yamnet/1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading YAMNet from TensorFlow Hub...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m yamnet_model = \u001b[43mhub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYAMNET_HANDLE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYAMNet loaded.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GW Classes/Fall 2025/Neural Networks and Deep Learning CSCI_6366_80/Audio Classification/audio-classification-cnn/.venv/lib/python3.11/site-packages/tensorflow_hub/module_v2.py:100\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(handle, tags, options)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     99\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mExpected a string, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % handle)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m module_path = \u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m is_hub_module_v1 = tf.io.gfile.exists(_get_module_proto_path(module_path))\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_hub_module_v1:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GW Classes/Fall 2025/Neural Networks and Deep Learning CSCI_6366_80/Audio Classification/audio-classification-cnn/.venv/lib/python3.11/site-packages/tensorflow_hub/module_v2.py:55\u001b[39m, in \u001b[36mresolve\u001b[39m\u001b[34m(handle)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresolve\u001b[39m(handle):\n\u001b[32m     32\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Resolves a module handle into a path.\u001b[39;00m\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m \u001b[33;03m  This function works both for plain TF2 SavedModels and the legacy TF1 Hub\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m \u001b[33;03m    A string representing the Module path.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregistry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GW Classes/Fall 2025/Neural Networks and Deep Learning CSCI_6366_80/Audio Classification/audio-classification-cnn/.venv/lib/python3.11/site-packages/tensorflow_hub/registry.py:49\u001b[39m, in \u001b[36mMultiImplRegister.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m._impls):\n\u001b[32m     48\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m impl.is_supported(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     51\u001b[39m     fails.append(\u001b[38;5;28mtype\u001b[39m(impl).\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GW Classes/Fall 2025/Neural Networks and Deep Learning CSCI_6366_80/Audio Classification/audio-classification-cnn/.venv/lib/python3.11/site-packages/tensorflow_hub/compressed_module_resolver.py:81\u001b[39m, in \u001b[36mHttpCompressedFileResolver.__call__\u001b[39m\u001b[34m(self, handle)\u001b[39m\n\u001b[32m     77\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._call_urlopen(request)\n\u001b[32m     78\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m resolver.DownloadManager(handle).download_and_uncompress(\n\u001b[32m     79\u001b[39m       response, tmp_dir)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43matomic_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lock_file_timeout_sec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GW Classes/Fall 2025/Neural Networks and Deep Learning CSCI_6366_80/Audio Classification/audio-classification-cnn/.venv/lib/python3.11/site-packages/tensorflow_hub/resolver.py:421\u001b[39m, in \u001b[36matomic_download\u001b[39m\u001b[34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[39m\n\u001b[32m    419\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mDownloading TF-Hub Module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, handle)\n\u001b[32m    420\u001b[39m tf.compat.v1.gfile.MakeDirs(tmp_dir)\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m \u001b[43mdownload_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# Write module descriptor to capture information about which module was\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# downloaded by whom and when. The file stored at the same level as a\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;66;03m# directory in order to keep the content of the 'model_dir' exactly as it\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# module caching protocol and no code in the TF-Hub library reads its\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# content.\u001b[39;00m\n\u001b[32m    431\u001b[39m _write_module_descriptor_file(handle, module_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GW Classes/Fall 2025/Neural Networks and Deep Learning CSCI_6366_80/Audio Classification/audio-classification-cnn/.venv/lib/python3.11/site-packages/tensorflow_hub/compressed_module_resolver.py:77\u001b[39m, in \u001b[36mHttpCompressedFileResolver.__call__.<locals>.download\u001b[39m\u001b[34m(handle, tmp_dir)\u001b[39m\n\u001b[32m     71\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m resolver.DownloadManager(handle).download_and_uncompress(\n\u001b[32m     72\u001b[39m       response, tmp_dir\n\u001b[32m     73\u001b[39m   )\n\u001b[32m     75\u001b[39m request = urllib.request.Request(\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._append_compressed_format_query(handle))\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_urlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resolver.DownloadManager(handle).download_and_uncompress(\n\u001b[32m     79\u001b[39m     response, tmp_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GW Classes/Fall 2025/Neural Networks and Deep Learning CSCI_6366_80/Audio Classification/audio-classification-cnn/.venv/lib/python3.11/site-packages/tensorflow_hub/resolver.py:528\u001b[39m, in \u001b[36mHttpResolverBase._call_urlopen\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    526\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m urllib.request.urlopen(request)\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:519\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    516\u001b[39m     req = meth(req)\n\u001b[32m    518\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    522\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:536\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    535\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1391\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1351\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1348\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1349\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1352\u001b[39m     r = h.getresponse()\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)>"
     ]
    }
   ],
   "source": [
    "# YAMNet TF Hub handle (internet needed the first time you run this)\n",
    "YAMNET_HANDLE = \"https://tfhub.dev/google/yamnet/1\"\n",
    "\n",
    "# Fix SSL certificate issue on macOS (if needed)\n",
    "import ssl\n",
    "import certifi\n",
    "import os\n",
    "\n",
    "# Set SSL certificate path for TensorFlow Hub downloads\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "\n",
    "print(\"Loading YAMNet from TensorFlow Hub...\")\n",
    "try:\n",
    "    yamnet_model = hub.load(YAMNET_HANDLE)\n",
    "    print(\"YAMNet loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YAMNet: {e}\")\n",
    "    print(\"\\nIf you see an SSL certificate error, try:\")\n",
    "    print(\"1. Install certifi: pip install certifi\")\n",
    "    print(\"2. Or run: /Applications/Python\\\\ 3.11/Install\\\\ Certificates.command\")\n",
    "    print(\"3. Or manually download YAMNet and use a local path\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add8661",
   "metadata": {},
   "source": [
    "## 5. Helper Functions: Waveforms → YAMNet Embeddings\n",
    "\n",
    "We now define:\n",
    "\n",
    "- `load_waveform(path)`: load a mono waveform at 16 kHz using `librosa`.\n",
    "- `yamnet_embedding_for_file(path)`: run YAMNet and average frame-level\n",
    "  embeddings to get a single 1024-D vector.\n",
    "- `compute_embeddings(file_paths)`: apply this to a list of paths and\n",
    "  return an array of shape `(N, embedding_dim)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_waveform(path: Path, sample_rate: int = SAMPLE_RATE) -> np.ndarray:\n",
    "    \"\"\"Load a mono waveform at the desired sample rate.\"\"\"\n",
    "    y, sr = librosa.load(path, sr=sample_rate, mono=True)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "def yamnet_embedding_for_file(path: Path) -> np.ndarray:\n",
    "    \"\"\"Compute a single YAMNet embedding vector for one audio file.\"\"\"\n",
    "    waveform = load_waveform(path)  # shape: (num_samples,)\n",
    "    \n",
    "    # YAMNet expects a batch dimension: (N, num_samples)\n",
    "    waveform_tf = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
    "    waveform_tf = tf.reshape(waveform_tf, [1, -1])\n",
    "    \n",
    "    # YAMNet returns (scores, embeddings, spectrogram)\n",
    "    scores, embeddings, spectrogram = yamnet_model(waveform_tf)\n",
    "    # embeddings shape: (num_frames, 1024)\n",
    "    \n",
    "    # Average over time frames to get a single 1024-D vector\n",
    "    embedding_mean = tf.reduce_mean(embeddings, axis=0)  # shape: (1024,)\n",
    "    return embedding_mean.numpy()\n",
    "\n",
    "def compute_embeddings(file_paths: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute YAMNet embeddings for a list/array of file paths.\"\"\"\n",
    "    all_embeddings = []\n",
    "    for i, path in enumerate(file_paths):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Processing file {i}/{len(file_paths)}: {path.name}\")\n",
    "        emb = yamnet_embedding_for_file(path)\n",
    "        all_embeddings.append(emb)\n",
    "    return np.stack(all_embeddings, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f8b36",
   "metadata": {},
   "source": [
    "## 6. Build Embeddings for Train / Validation / Test\n",
    "\n",
    "We now compute YAMNet embeddings for:\n",
    "\n",
    "- `paths_train` → `X_train_embed`\n",
    "- `paths_val` → `X_val_embed`\n",
    "- `paths_test` → `X_test_embed`\n",
    "\n",
    "Then we convert integer labels (`0,1,2`) into one-hot vectors of length 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings (this may take some time on CPU)\n",
    "X_train_embed = compute_embeddings(paths_train)\n",
    "X_val_embed = compute_embeddings(paths_val)\n",
    "X_test_embed = compute_embeddings(paths_test)\n",
    "\n",
    "print(\"Embedding shapes:\")\n",
    "print(\"  Train:\", X_train_embed.shape)\n",
    "print(\"  Val:  \", X_val_embed.shape)\n",
    "print(\"  Test: \", X_test_embed.shape)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(CLASS_NAMES)\n",
    "\n",
    "def to_one_hot(y_int: np.ndarray, num_classes: int) -> np.ndarray:\n",
    "    y_one_hot = np.zeros((len(y_int), num_classes), dtype=np.float32)\n",
    "    for i, idx in enumerate(y_int):\n",
    "        y_one_hot[i, idx] = 1.0\n",
    "    return y_one_hot\n",
    "\n",
    "y_train_oh = to_one_hot(y_train, num_classes)\n",
    "y_val_oh = to_one_hot(y_val, num_classes)\n",
    "y_test_oh = to_one_hot(y_test, num_classes)\n",
    "\n",
    "print(\"Label shapes (one-hot):\")\n",
    "print(\"  Train:\", y_train_oh.shape)\n",
    "print(\"  Val:  \", y_val_oh.shape)\n",
    "print(\"  Test: \", y_test_oh.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d5b6a",
   "metadata": {},
   "source": [
    "## 7. Plotting Helper for Training Curves\n",
    "\n",
    "We reuse the same helper function to plot training and validation loss\n",
    "and accuracy over epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history, title_prefix=\"\"):\n",
    "    \"\"\"Plot training and validation loss/accuracy.\"\"\"\n",
    "    history_dict = history.history\n",
    "\n",
    "    train_loss = history_dict.get(\"loss\", [])\n",
    "    val_loss = history_dict.get(\"val_loss\", [])\n",
    "    train_acc = history_dict.get(\"accuracy\", [])\n",
    "    val_acc = history_dict.get(\"val_accuracy\", [])\n",
    "\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, label=\"Train loss\")\n",
    "    if val_loss:\n",
    "        plt.plot(epochs, val_loss, label=\"Val loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{title_prefix} Training vs Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc, label=\"Train acc\")\n",
    "    if val_acc:\n",
    "        plt.plot(epochs, val_acc, label=\"Val acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{title_prefix} Training vs Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6208e",
   "metadata": {},
   "source": [
    "## 8. Define the Transfer-Learning Classifier\n",
    "\n",
    "We now define a simple classifier that takes YAMNet embeddings as input:\n",
    "\n",
    "- Input: 1024-D embedding vector\n",
    "- Dense(128, ReLU) + Dropout(0.3)\n",
    "- Dense(3, Softmax)\n",
    "\n",
    "We use the same loss and optimizer as before (`categorical_crossentropy` +\n",
    "`adam`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_yamnet_classifier(input_dim: int, num_classes: int = 3, dropout_rate: float = 0.3):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_dim = X_train_embed.shape[1]\n",
    "yamnet_model_head = build_yamnet_classifier(input_dim=input_dim, num_classes=num_classes)\n",
    "yamnet_model_head.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf6781",
   "metadata": {},
   "source": [
    "## 9. Training the YAMNet Embedding Classifier\n",
    "\n",
    "We train the classifier on top of YAMNet embeddings using the same\n",
    "train/validation split as before.\n",
    "\n",
    "- Epochs: 20\n",
    "- Batch size: 16\n",
    "\n",
    "(You can adjust these if training is very fast or slow.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab46f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "yamnet_history = yamnet_model_head.fit(\n",
    "    X_train_embed,\n",
    "    y_train_oh,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val_embed, y_val_oh),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "plot_training_curves(yamnet_history, title_prefix=\"YAMNet Embedding Classifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99dce9",
   "metadata": {},
   "source": [
    "## 10. Evaluation on the Held-out Test Set\n",
    "\n",
    "We now evaluate the YAMNet-based classifier on the test set (92 clips),\n",
    "and compute:\n",
    "\n",
    "- Test loss and accuracy\n",
    "- Confusion matrix\n",
    "- Per-class precision, recall, and F1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252598a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_embeddings(model, X_test, y_test_oh, y_test_int, model_name=\"Model\"):\n",
    "    \"\"\"Evaluate a classifier on embedding features and print metrics.\"\"\"\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test_oh, verbose=0)\n",
    "    print(f\"{model_name} - Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    cm = confusion_matrix(y_test_int, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test_int, y_pred, target_names=CLASS_NAMES))\n",
    "\n",
    "    return test_loss, test_acc, cm\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"YAMNet Embedding Classifier RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "yamnet_results = evaluate_model_embeddings(\n",
    "    yamnet_model_head,\n",
    "    X_test_embed,\n",
    "    y_test_oh,\n",
    "    y_test,\n",
    "    model_name=\"YAMNet + Dense Head\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
