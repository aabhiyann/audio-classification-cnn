{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8503123c",
   "metadata": {},
   "source": [
    "## 04: Full Data CNN Experiments\n",
    "\n",
    "**Course:** CSCI 6366 (Neural Networks and Deep Learning)  \n",
    "**Project:** Audio Classification using CNN  \n",
    "**Notebook:** Full Data CNN Experiments\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook we scale up from the small 60-sample subset used in\n",
    "`03_cnn_improved.ipynb` to a much larger portion of the dataset.\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "- Use many more of the available 610 audio files (dog/cat/bird).\n",
    "- Train and compare our **baseline CNN** and a **regularized variant**\n",
    "  on a proper train/validation/test split.\n",
    "- Report final test accuracy, confusion matrix, and per-class metrics.\n",
    "- Summarize which architecture works best when given more data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a3389",
   "metadata": {},
   "source": [
    "### 1. Setup and Configuration\n",
    "\n",
    "In this section we:\n",
    "- import the same libraries used in previous notebooks,\n",
    "- set global parameters (sample rate, Mel-spectrogram settings, etc.),\n",
    "- configure how many files per class to use,\n",
    "- and fix random seeds for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf41581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "\n",
    "# Audio / mel-spectrogram parameters (same as previous notebooks)\n",
    "SAMPLE_RATE = 16000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "N_MELS = 128\n",
    "\n",
    "CLASS_NAMES = [\"dog\", \"cat\", \"bird\"]\n",
    "label_to_index = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n",
    "\n",
    "# How many files per class to use (None = use all)\n",
    "MAX_FILES_PER_CLASS = None  # or e.g. 150\n",
    "\n",
    "# Train/val/test ratios\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15  # of the remaining after test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20190410",
   "metadata": {},
   "source": [
    "## 2. Helper Functions for Preprocessing\n",
    "\n",
    "We reuse the same preprocessing pipeline as in previous notebooks to ensure consistency:\n",
    "\n",
    "1. Load the raw audio file with `librosa.load` at 16 kHz.\n",
    "2. Convert to a Mel-spectrogram with `librosa.feature.melspectrogram`.\n",
    "3. Convert to log scale (`librosa.power_to_db`) and normalize to [0, 1].\n",
    "4. Pad or crop each spectrogram to a fixed 128×128 window.\n",
    "5. Add channel dimension to get shape (128, 128, 1).\n",
    "6. Stack them into arrays `X` (inputs) and `y` (one-hot labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c5c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mel_spectrogram(path, sample_rate=SAMPLE_RATE, n_fft=N_FFT,\n",
    "                         hop_length=HOP_LENGTH, n_mels=N_MELS):\n",
    "    y, sr = librosa.load(path, sr=sample_rate)\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        power=2.0,\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    # Normalize roughly to [0, 1]\n",
    "    S_norm = (S_db - S_db.min()) / (S_db.max() - S_db.min() + 1e-8)\n",
    "    return S_norm\n",
    "\n",
    "\n",
    "def pad_or_crop_spectrogram(S, target_time_bins=128):\n",
    "    n_mels, n_frames = S.shape\n",
    "\n",
    "    if n_mels != N_MELS:\n",
    "        raise ValueError(f\"Expected {N_MELS} Mel bands, got {n_mels}\")\n",
    "\n",
    "    if n_frames == target_time_bins:\n",
    "        return S\n",
    "\n",
    "    if n_frames < target_time_bins:\n",
    "        pad_width = target_time_bins - n_frames\n",
    "        S_padded = np.pad(S, ((0, 0), (0, pad_width)), mode=\"constant\")\n",
    "        return S_padded\n",
    "\n",
    "    # If too long, centrally crop\n",
    "    start = (n_frames - target_time_bins) // 2\n",
    "    end = start + target_time_bins\n",
    "    return S[:, start:end]\n",
    "\n",
    "\n",
    "def load_example_for_model(audio_path: Path, label: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load one audio file and return (X, y) ready for model.\"\"\"\n",
    "    S_norm = load_mel_spectrogram(audio_path)\n",
    "    S_fixed = pad_or_crop_spectrogram(S_norm, target_time_bins=128)\n",
    "\n",
    "    # Add channel dimension → (128, 128, 1)\n",
    "    X = S_fixed.astype(\"float32\")[..., np.newaxis]\n",
    "\n",
    "    # One-hot label\n",
    "    num_classes = len(CLASS_NAMES)\n",
    "    y = np.zeros(num_classes, dtype=\"float32\")\n",
    "    y[label_to_index[label]] = 1.0\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_dataset_full(max_files_per_class: int | None = MAX_FILES_PER_CLASS):\n",
    "    \"\"\"Load many files per class (or all if max_files_per_class is None).\"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for label in CLASS_NAMES:\n",
    "        class_dir = DATA_DIR / label\n",
    "        wav_files = sorted(class_dir.glob(\"*.wav\"))\n",
    "\n",
    "        if max_files_per_class is not None:\n",
    "            wav_files = wav_files[:max_files_per_class]\n",
    "\n",
    "        for audio_path in wav_files:\n",
    "            X, y = load_example_for_model(audio_path, label)\n",
    "            X_list.append(X)\n",
    "            y_list.append(y)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.stack(y_list, axis=0)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f69897",
   "metadata": {},
   "source": [
    "## 3. Load Full Dataset\n",
    "\n",
    "Load the dataset using the helper functions. If `MAX_FILES_PER_CLASS` is `None`, we'll use all available files. Otherwise, we'll limit to the specified number per class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset_full(MAX_FILES_PER_CLASS)\n",
    "print(\"Dataset shapes:\", X.shape, y.shape)\n",
    "\n",
    "y_indices = np.argmax(y, axis=1)\n",
    "unique, counts = np.unique(y_indices, return_counts=True)\n",
    "for idx, count in zip(unique, counts):\n",
    "    print(f\"{CLASS_NAMES[idx]}: {count} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7d755",
   "metadata": {},
   "source": [
    "### 3.1 Dataset Summary\n",
    "\n",
    "The dataset has been loaded with the specified number of files per class. This gives us a much larger training set compared to the initial 60-sample subset used in earlier experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10078b17",
   "metadata": {},
   "source": [
    "## 4. Train / Validation / Test Split\n",
    "\n",
    "We create explicit train, validation, and test sets using stratified splits so that each set has a similar class distribution. This ensures fair evaluation and prevents class imbalance issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split off test set\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=42,\n",
    "    stratify=y_indices,\n",
    ")\n",
    "\n",
    "# Need class indices for stratified split again\n",
    "y_train_full_idx = np.argmax(y_train_full, axis=1)\n",
    "\n",
    "# Now split train_full into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=VAL_SIZE,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full_idx,\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "# Show class distribution in each split\n",
    "print(\"\\nClass distribution:\")\n",
    "for split_name, y_split in [(\"Train\", y_train), (\"Validation\", y_val), (\"Test\", y_test)]:\n",
    "    y_split_idx = np.argmax(y_split, axis=1)\n",
    "    unique, counts = np.unique(y_split_idx, return_counts=True)\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    for idx, count in zip(unique, counts):\n",
    "        print(f\"  {CLASS_NAMES[idx]}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810096e",
   "metadata": {},
   "source": [
    "### 4.1 Split Summary\n",
    "\n",
    "We now have:\n",
    "- `X_train`: training inputs (used to train the model)\n",
    "- `X_val`: validation inputs (used during training to monitor generalization)\n",
    "- `X_test`: held-out test inputs (used only at the end for final evaluation)\n",
    "\n",
    "All splits are stratified, so each class appears in similar proportions across train, validation, and test sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2707256d",
   "metadata": {},
   "source": [
    "## 5. Plotting Helper Function\n",
    "\n",
    "We'll reuse the `plot_training_curves` function to visualize training progress for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d928416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history, title_prefix=\"\"):\n",
    "    \"\"\"Plot training and validation loss/accuracy.\"\"\"\n",
    "    history_dict = history.history\n",
    "\n",
    "    train_loss = history_dict.get(\"loss\", [])\n",
    "    val_loss = history_dict.get(\"val_loss\", [])\n",
    "    train_acc = history_dict.get(\"accuracy\", [])\n",
    "    val_acc = history_dict.get(\"val_accuracy\", [])\n",
    "\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, label=\"Train loss\")\n",
    "    if val_loss:\n",
    "        plt.plot(epochs, val_loss, label=\"Val loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{title_prefix} Training vs Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc, label=\"Train acc\")\n",
    "    if val_acc:\n",
    "        plt.plot(epochs, val_acc, label=\"Val acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{title_prefix} Training vs Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7de1d4",
   "metadata": {},
   "source": [
    "## 6. Define Candidate Models\n",
    "\n",
    "We'll train and compare two models:\n",
    "\n",
    "1. **Baseline CNN**: The same architecture from `02_cnn_baseline.ipynb` (Dense 64, no regularization)\n",
    "2. **Regularized CNN**: Baseline architecture with Dropout (0.3) added before the final classification layer\n",
    "\n",
    "The goal is to see whether regularization helps when we have more data, compared to the small dataset experiments where Dropout(0.5) was too strong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7694a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_baseline_cnn(input_shape=(128, 128, 1), num_classes=3):\n",
    "    \"\"\"Baseline CNN architecture (same as notebook 02).\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=input_shape),\n",
    "\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_cnn_with_dropout(input_shape=(128, 128, 1), num_classes=3, dropout_rate=0.3):\n",
    "    \"\"\"Baseline CNN with Dropout regularization.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=input_shape),\n",
    "\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62548e6",
   "metadata": {},
   "source": [
    "## 7. Train Model A: Baseline CNN\n",
    "\n",
    "Train the baseline CNN model on the full dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b90d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "baseline_model = build_baseline_cnn()\n",
    "baseline_model.summary()\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "plot_training_curves(baseline_history, title_prefix=\"Baseline CNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de2e48",
   "metadata": {},
   "source": [
    "## 8. Train Model B: CNN with Dropout\n",
    "\n",
    "Train the regularized CNN model with Dropout(0.3) on the same dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c32f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_model = build_cnn_with_dropout()\n",
    "drop_model.summary()\n",
    "\n",
    "drop_history = drop_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "plot_training_curves(drop_history, title_prefix=\"CNN + Dropout (0.3)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be1da5",
   "metadata": {},
   "source": [
    "## 9. Evaluate Models on Test Set\n",
    "\n",
    "Evaluate both models on the held-out test set and generate:\n",
    "- Test accuracy and loss\n",
    "- Confusion matrix\n",
    "- Per-class classification report (precision, recall, F1-score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6af0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    \"\"\"Evaluate model and print metrics.\"\"\"\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"{model_name} - Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
    "\n",
    "    return test_loss, test_acc, cm\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BASELINE CNN RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "baseline_results = evaluate_model(baseline_model, X_test, y_test, model_name=\"Baseline CNN\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CNN + DROPOUT (0.3) RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "drop_results = evaluate_model(drop_model, X_test, y_test, model_name=\"CNN + Dropout (0.3)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c58f5",
   "metadata": {},
   "source": [
    "## 10. Summary of Full-Data Experiments\n",
    "\n",
    "Here we summarize the performance of our two candidate models on the larger dataset:\n",
    "\n",
    "- **Baseline CNN** (Dense 64, no regularization)\n",
    "- **CNN with Dropout** (Dense 64 + Dropout 0.3)\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "*(Fill in after running the experiments)*\n",
    "\n",
    "- **Baseline CNN**:\n",
    "  - Final training accuracy: ???\n",
    "  - Final validation accuracy: ???\n",
    "  - Test accuracy: ???\n",
    "  - Test loss: ???\n",
    "\n",
    "- **CNN + Dropout (0.3)**:\n",
    "  - Final training accuracy: ???\n",
    "  - Final validation accuracy: ???\n",
    "  - Test accuracy: ???\n",
    "  - Test loss: ???\n",
    "\n",
    "### Discussion\n",
    "\n",
    "**Which model generalizes better?**\n",
    "\n",
    "*(Fill in after seeing results)*\n",
    "\n",
    "**Did Dropout help when we have more data?**\n",
    "\n",
    "*(Fill in after seeing results - compare to the small dataset experiments where Dropout(0.5) was too strong)*\n",
    "\n",
    "**Which model do we choose as our final one for the project?**\n",
    "\n",
    "*(Fill in after seeing results)*\n",
    "\n",
    "### Comparison with Small Dataset Experiments\n",
    "\n",
    "In `03_cnn_improved.ipynb`, we found that:\n",
    "- Baseline (Dense 64) achieved ~60% val accuracy and ~42% test accuracy on 60 samples\n",
    "- Dropout(0.5) was too strong and hurt performance (test acc dropped to ~33%)\n",
    "\n",
    "With the larger dataset, we expect:\n",
    "- More reliable validation metrics (less noise)\n",
    "- Better overall performance due to more training data\n",
    "- Dropout(0.3) may be more effective than Dropout(0.5) was on the small dataset\n",
    "\n",
    "*(Update this section after running experiments)*\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
