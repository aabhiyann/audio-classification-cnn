{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9102e4c",
   "metadata": {},
   "source": [
    "# 03 – Improved CNN Experiments\n",
    "\n",
    "In this notebook we start from the baseline CNN developed in\n",
    "`02_cnn_baseline.ipynb` and explore simple improvements to:\n",
    "\n",
    "- reduce overfitting,\n",
    "- improve validation and test accuracy,\n",
    "- and understand how model capacity and regularization affect performance.\n",
    "\n",
    "We keep the same data preprocessing and train/validation/test split so that\n",
    "results are directly comparable to the baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13850a26",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "In this section we:\n",
    "\n",
    "- import the same libraries used in the baseline notebook,\n",
    "- set global parameters (sample rate, Mel-spectrogram settings, etc.),\n",
    "- and fix random seeds for reproducibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f43b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make sure we see same results each run\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Data directory (adjust if needed)\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "\n",
    "# Audio/mel-spectrogram parameters\n",
    "SAMPLE_RATE = 16000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "N_MELS = 128\n",
    "\n",
    "# Train/val/test split ratios\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2  # of the remaining training pool\n",
    "\n",
    "# Class labels\n",
    "CLASS_NAMES = [\"dog\", \"cat\", \"bird\"]\n",
    "label_to_index = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6c46f",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "We reuse the same preprocessing pipeline as in the baseline notebook:\n",
    "\n",
    "1. Load the raw audio file with `librosa.load` at 16 kHz.\n",
    "2. Convert to a Mel-spectrogram with `librosa.feature.melspectrogram`.\n",
    "3. Convert to log scale (`librosa.power_to_db`) and normalize.\n",
    "4. Pad or crop each spectrogram to a fixed 128×128 window.\n",
    "5. Stack them into arrays `X` (inputs) and `y` (one-hot labels).\n",
    "\n",
    "For clarity, we keep the helper functions here in this notebook. Later, they\n",
    "could be moved into a shared `src/` module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cb523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mel_spectrogram(path, sample_rate=SAMPLE_RATE, n_fft=N_FFT,\n",
    "                         hop_length=HOP_LENGTH, n_mels=N_MELS):\n",
    "    y, sr = librosa.load(path, sr=sample_rate)\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        power=2.0,\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    # Normalize roughly to [0, 1]\n",
    "    S_norm = (S_db - S_db.min()) / (S_db.max() - S_db.min() + 1e-8)\n",
    "    return S_norm\n",
    "\n",
    "def pad_or_crop_spectrogram(S, target_time_bins=128):\n",
    "    n_mels, n_frames = S.shape\n",
    "\n",
    "    if n_mels != N_MELS:\n",
    "        raise ValueError(f\"Expected {N_MELS} Mel bands, got {n_mels}\")\n",
    "\n",
    "    if n_frames == target_time_bins:\n",
    "        return S\n",
    "\n",
    "    if n_frames < target_time_bins:\n",
    "        # Pad with zeros along time axis\n",
    "        pad_width = target_time_bins - n_frames\n",
    "        S_padded = np.pad(S, ((0, 0), (0, pad_width)), mode=\"constant\")\n",
    "        return S_padded\n",
    "\n",
    "    # If too long, centrally crop\n",
    "    start = (n_frames - target_time_bins) // 2\n",
    "    end = start + target_time_bins\n",
    "    return S[:, start:end]\n",
    "\n",
    "def load_example_for_model(audio_path: Path, label: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load one audio file and return (X, y) ready for model.\"\"\"\n",
    "    S_norm = load_mel_spectrogram(audio_path)\n",
    "    S_fixed = pad_or_crop_spectrogram(S_norm, target_time_bins=128)\n",
    "    \n",
    "    # Add channel dimension → (128, 128, 1)\n",
    "    X = S_fixed.astype(\"float32\")[..., np.newaxis]\n",
    "    \n",
    "    # One-hot label\n",
    "    num_classes = len(CLASS_NAMES)\n",
    "    y = np.zeros(num_classes, dtype=\"float32\")\n",
    "    y[label_to_index[label]] = 1.0\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_dataset(max_files_per_class: int = 20):\n",
    "    \"\"\"Load dataset with same structure as baseline.\"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for label in CLASS_NAMES:\n",
    "        class_dir = DATA_DIR / label\n",
    "        wav_files = sorted(class_dir.glob(\"*.wav\"))\n",
    "        \n",
    "        for audio_path in wav_files[:max_files_per_class]:\n",
    "            X, y = load_example_for_model(audio_path, label)\n",
    "            X_list.append(X)\n",
    "            y_list.append(y)\n",
    "    \n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.stack(y_list, axis=0)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328de8f",
   "metadata": {},
   "source": [
    "### 2.1 Load dataset into `X` and `y`\n",
    "\n",
    "Next we apply these helper functions to the dataset directory and build:\n",
    "\n",
    "- `X`: array of shape `(num_examples, 128, 128, 1)`\n",
    "- `y`: one-hot labels of shape `(num_examples, 3)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ce0312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: X=(60, 128, 128, 1), y=(60, 3)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset(max_files_per_class=20)\n",
    "print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf436d5",
   "metadata": {},
   "source": [
    "## 3. Train / Validation / Test Split\n",
    "\n",
    "We create explicit train, validation, and test sets using stratified splits\n",
    "so that each set has a similar class distribution. This mirrors the split\n",
    "used in the baseline notebook to keep results comparable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628b453c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38, 128, 128, 1), (10, 128, 128, 1), (12, 128, 128, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume X, y are already built\n",
    "y_indices = np.argmax(y, axis=1)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test, y_train_full_idx, y_test_idx = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    y_indices,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=42,\n",
    "    stratify=y_indices,\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=VAL_SIZE,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full_idx,\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967a293",
   "metadata": {},
   "source": [
    "We now have:\n",
    "\n",
    "- `X_train`: training inputs\n",
    "- `X_val`: validation inputs (used during training to monitor generalization)\n",
    "- `X_test`: held-out test inputs (used only at the end for final evaluation)\n",
    "\n",
    "All splits are stratified, so each class appears in similar proportions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4e499",
   "metadata": {},
   "source": [
    "## 4. Experiment 1 – Smaller Dense Layer\n",
    "\n",
    "In the baseline model, the Dense(64) layer after Flatten accounts for the\n",
    "majority of parameters (~4.2M) and likely contributes to overfitting.\n",
    "\n",
    "In this experiment we:\n",
    "\n",
    "- Keep the convolution + pooling part the same as the baseline.\n",
    "- Replace `Dense(64, relu)` with `Dense(32, relu)` (fewer parameters).\n",
    "- Train the model with the same settings as the baseline.\n",
    "- Compare validation and test accuracy to see if a smaller dense layer\n",
    "  improves generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea32dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m2,097,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,116,099</span> (8.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,116,099\u001b[0m (8.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,116,099</span> (8.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,116,099\u001b[0m (8.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_cnn_small_dense(input_shape=(128, 128, 1), num_classes=3):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=input_shape),\n",
    "\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation=\"relu\"),  # smaller dense layer\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "small_dense_model = build_cnn_small_dense()\n",
    "small_dense_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b1444",
   "metadata": {},
   "source": [
    "### 4.1 Training the small-dense model\n",
    "\n",
    "We now train the model on the same train/validation split and reuse the\n",
    "`plot_training_curves` function from the baseline notebook to visualize\n",
    "loss and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215e5f2",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db824e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training code will go here\n",
    "# history_small_dense = small_dense_model.fit(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47ef55",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3e89a",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eaed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db46dc1",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f040f0",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74189e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff0b32",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
