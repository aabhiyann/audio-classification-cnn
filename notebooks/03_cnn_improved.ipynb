{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9102e4c",
   "metadata": {},
   "source": [
    "# Audio Classification: Improved CNN Models\n",
    "\n",
    "**Course:** CSCI 6366 (Neural Networks and Deep Learning)  \n",
    "**Project:** Audio Classification using CNN  \n",
    "**Notebook:** Improved CNN Architectures and Regularization Experiments\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook builds on the baseline CNN from `02_cnn_baseline.ipynb` and explores improvements to reduce overfitting and improve generalization. We will:\n",
    "\n",
    "1. **Reuse the same data preprocessing pipeline** from the baseline (Mel-spectrograms, 128×128, normalization).\n",
    "2. **Experiment with improved architectures**:\n",
    "   - Smaller Dense layers to reduce parameter count\n",
    "   - Dropout regularization\n",
    "   - Potentially other architectural tweaks\n",
    "3. **Compare results** against the baseline model using the same train/val/test splits.\n",
    "4. **Report metrics** including accuracy, loss curves, and potentially confusion matrices.\n",
    "\n",
    "The goal is to find a model that generalizes better than the baseline while maintaining reasonable training performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13850a26",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "**Goal:** Import necessary libraries and set up configuration constants.\n",
    "\n",
    "- Standard libraries: `numpy`, `pathlib` for data handling\n",
    "- Audio processing: `librosa` for Mel-spectrogram computation\n",
    "- Deep learning: `tensorflow` / `keras` for model building\n",
    "- Evaluation: `sklearn` for train/test splits and metrics\n",
    "- Visualization: `matplotlib` for plotting training curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration (same as baseline)\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "CLASS_NAMES = [\"dog\", \"cat\", \"bird\"]\n",
    "label_to_index = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6c46f",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "**Goal:** Reuse the exact same preprocessing functions from the baseline to ensure fair comparison.\n",
    "\n",
    "- Load audio files and convert to Mel-spectrograms (128×128)\n",
    "- Normalize to [0, 1] range\n",
    "- Create one-hot encoded labels\n",
    "- Use the same train/val/test split strategy with stratification\n",
    "\n",
    "This ensures that any performance differences come from model architecture changes, not data differences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse preprocessing functions from baseline (or import if refactored)\n",
    "def load_mel_spectrogram(\n",
    "    audio_path: Path,\n",
    "    sr: int = 16000,\n",
    "    n_fft: int = 1024,\n",
    "    hop_length: int = 512,\n",
    "    n_mels: int = 128,\n",
    ") -> tuple[np.ndarray, int]:\n",
    "    \"\"\"Load an audio file and compute its Mel-spectrogram in dB scale.\"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, power=2.0\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    return S_db, sr\n",
    "\n",
    "def pad_or_crop_spectrogram(S_db: np.ndarray, target_shape=(128, 128)) -> np.ndarray:\n",
    "    \"\"\"Ensure the Mel-spectrogram has shape (target_height, target_width).\"\"\"\n",
    "    target_height, target_width = target_shape\n",
    "    n_mels, time_frames = S_db.shape\n",
    "    \n",
    "    if n_mels != target_height:\n",
    "        raise ValueError(f\"Expected {target_height} mel bands, got {n_mels}\")\n",
    "    \n",
    "    if time_frames > target_width:\n",
    "        start = (time_frames - target_width) // 2\n",
    "        end = start + target_width\n",
    "        S_db = S_db[:, start:end]\n",
    "    elif time_frames < target_width:\n",
    "        pad_width = target_width - time_frames\n",
    "        S_db = np.pad(\n",
    "            S_db,\n",
    "            pad_width=((0, 0), (0, pad_width)),\n",
    "            mode=\"constant\",\n",
    "            constant_values=(S_db.min(),),\n",
    "        )\n",
    "    return S_db\n",
    "\n",
    "def load_example_for_model(audio_path: Path, label: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load one audio file and return (X, y) ready for model.\"\"\"\n",
    "    S_db, sr = load_mel_spectrogram(audio_path)\n",
    "    S_fixed = pad_or_crop_spectrogram(S_db, target_shape=(128, 128))\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    S_min = S_fixed.min()\n",
    "    S_max = S_fixed.max()\n",
    "    S_norm = (S_fixed - S_min) / (S_max - S_min + 1e-8)\n",
    "    \n",
    "    # Add channel dimension\n",
    "    X = S_norm.astype(\"float32\")[..., np.newaxis]\n",
    "    \n",
    "    # One-hot label\n",
    "    num_classes = len(CLASS_NAMES)\n",
    "    y = np.zeros(num_classes, dtype=\"float32\")\n",
    "    y[label_to_index[label]] = 1.0\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_dataset(max_files_per_class: int = 20):\n",
    "    \"\"\"Load dataset with same structure as baseline.\"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for label in CLASS_NAMES:\n",
    "        class_dir = DATA_DIR / label\n",
    "        wav_files = sorted(class_dir.glob(\"*.wav\"))\n",
    "        \n",
    "        for audio_path in wav_files[:max_files_per_class]:\n",
    "            X, y = load_example_for_model(audio_path, label)\n",
    "            X_list.append(X)\n",
    "            y_list.append(y)\n",
    "    \n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.stack(y_list, axis=0)\n",
    "    return X, y\n",
    "\n",
    "# Load data\n",
    "X, y = load_dataset(max_files_per_class=20)\n",
    "print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328de8f",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split\n",
    "\n",
    "**Goal:** Create the same stratified splits as the baseline for fair comparison.\n",
    "\n",
    "- Use `random_state=42` to ensure reproducibility\n",
    "- 20% for test set (held out completely)\n",
    "- 20% of remaining data for validation\n",
    "- Rest for training\n",
    "- Stratify by class to maintain balanced proportions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to class indices for stratification\n",
    "y_indices = np.argmax(y, axis=1)\n",
    "\n",
    "# First split: test set (20%)\n",
    "X_train_full, X_test, y_train_full, y_test, y_train_full_idx, y_test_idx = train_test_split(\n",
    "    X, y, y_indices,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_indices,\n",
    ")\n",
    "\n",
    "# Second split: train/val from remaining (20% of train_full becomes val)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full_idx,\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf436d5",
   "metadata": {},
   "source": [
    "## Improved Model 1: Baseline with Dropout\n",
    "\n",
    "**Goal:** Add dropout regularization to the baseline architecture to reduce overfitting.\n",
    "\n",
    "- Keep the same architecture as baseline (Conv(32) → Pool → Conv(64) → Pool → Flatten → Dense(64) → Dense(3))\n",
    "- Add Dropout(0.5) after the Dense(64) layer\n",
    "- This should help prevent the model from memorizing training data\n",
    "\n",
    "Expected: Similar or slightly lower training accuracy, but better validation/test accuracy due to reduced overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 1)\n",
    "num_classes = len(CLASS_NAMES)\n",
    "\n",
    "model_dropout = models.Sequential([\n",
    "    tf.keras.Input(shape=input_shape),\n",
    "    \n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),  # Add dropout here\n",
    "    layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model_dropout.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_dropout.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967a293",
   "metadata": {},
   "source": [
    "### Training Model 1 (with Dropout)\n",
    "\n",
    "**Goal:** Train the dropout model with the same hyperparameters as baseline for fair comparison.\n",
    "\n",
    "- Optimizer: Adam\n",
    "- Loss: categorical crossentropy\n",
    "- Batch size: 8\n",
    "- Epochs: 10\n",
    "- Monitor validation accuracy to see if dropout helps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf4e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dropout = model_dropout.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=8,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428caee2",
   "metadata": {},
   "source": [
    "### Evaluation and Visualization\n",
    "\n",
    "**Goal:** Plot training curves and evaluate on test set to compare with baseline.\n",
    "\n",
    "- Plot training vs validation loss and accuracy\n",
    "- Evaluate on held-out test set\n",
    "- Compare numbers with baseline (train≈0.89, val≈0.60, test≈0.42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea32dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history, title=\"Training Curves\"):\n",
    "    \"\"\"Plot training and validation loss/accuracy.\"\"\"\n",
    "    history_dict = history.history\n",
    "    \n",
    "    train_loss = history_dict.get(\"loss\", [])\n",
    "    val_loss = history_dict.get(\"val_loss\", [])\n",
    "    train_acc = history_dict.get(\"accuracy\", [])\n",
    "    val_acc = history_dict.get(\"val_accuracy\", [])\n",
    "    \n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, label=\"Train loss\")\n",
    "    if val_loss:\n",
    "        plt.plot(epochs, val_loss, label=\"Val loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{title} - Loss\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc, label=\"Train acc\")\n",
    "    if val_acc:\n",
    "        plt.plot(epochs, val_acc, label=\"Val acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{title} - Accuracy\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_curves(history_dropout, title=\"Model 1: Baseline + Dropout\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss_dropout, test_acc_dropout = model_dropout.evaluate(X_test, y_test, batch_size=8, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss_dropout:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_dropout:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b1444",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "- What do we see in the plots/numbers?\n",
    "- Is it better or worse than baseline?\n",
    "- Any guess why?\n",
    "\n",
    "*(Fill this in after running the training and seeing the results)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215e5f2",
   "metadata": {},
   "source": [
    "## Improved Model 2: Smaller Dense Layer\n",
    "\n",
    "**Goal:** Reduce model capacity by using a smaller Dense layer to combat overfitting.\n",
    "\n",
    "- Same Conv layers as baseline\n",
    "- Reduce Dense(64) to Dense(32) to cut parameter count\n",
    "- This should reduce overfitting by making the model less expressive\n",
    "- Compare parameter count with baseline (~4.2M)\n",
    "\n",
    "Expected: Lower training accuracy but potentially better generalization if the baseline was overfitting due to too many parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db824e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small = models.Sequential([\n",
    "    tf.keras.Input(shape=input_shape),\n",
    "    \n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation=\"relu\"),  # Smaller: 64 → 32\n",
    "    layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model_small.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_small.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47ef55",
   "metadata": {},
   "source": [
    "### Training Model 2 (Smaller Dense)\n",
    "\n",
    "**Goal:** Train with same hyperparameters to isolate the effect of architecture change.\n",
    "\n",
    "- Same training setup as Model 1 and baseline\n",
    "- Monitor if smaller capacity helps generalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_small = model_small.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=8,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3e89a",
   "metadata": {},
   "source": [
    "### Evaluation Model 2\n",
    "\n",
    "**Goal:** Visualize results and get test metrics for comparison.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eaed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(history_small, title=\"Model 2: Smaller Dense Layer\")\n",
    "\n",
    "test_loss_small, test_acc_small = model_small.evaluate(X_test, y_test, batch_size=8, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss_small:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_small:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db46dc1",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "- What do we see in the plots/numbers?\n",
    "- Is it better or worse than baseline and Model 1?\n",
    "- Any guess why?\n",
    "\n",
    "*(Fill this in after running the training and seeing the results)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f040f0",
   "metadata": {},
   "source": [
    "## Model Comparison Summary\n",
    "\n",
    "**Goal:** Compare all models side-by-side to identify the best approach.\n",
    "\n",
    "- Create a table comparing train/val/test accuracies\n",
    "- Compare parameter counts\n",
    "- Identify which model generalizes best\n",
    "- Note any trade-offs (e.g., lower train acc but better test acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74189e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract final metrics from training histories\n",
    "train_acc_dropout = history_dropout.history['accuracy'][-1]\n",
    "val_acc_dropout = history_dropout.history['val_accuracy'][-1]\n",
    "train_loss_dropout = history_dropout.history['loss'][-1]\n",
    "val_loss_dropout = history_dropout.history['val_loss'][-1]\n",
    "\n",
    "train_acc_small = history_small.history['accuracy'][-1]\n",
    "val_acc_small = history_small.history['val_accuracy'][-1]\n",
    "train_loss_small = history_small.history['loss'][-1]\n",
    "val_loss_small = history_small.history['val_loss'][-1]\n",
    "\n",
    "# Baseline numbers (from 02_cnn_baseline.ipynb)\n",
    "baseline_train_acc = 0.89\n",
    "baseline_val_acc = 0.60\n",
    "baseline_test_acc = 0.42\n",
    "baseline_train_loss = 0.48\n",
    "baseline_val_loss = 0.94\n",
    "baseline_test_loss = 1.12\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<25} {'Train Acc':<12} {'Val Acc':<12} {'Test Acc':<12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Baseline':<25} {baseline_train_acc:<12.4f} {baseline_val_acc:<12.4f} {baseline_test_acc:<12.4f}\")\n",
    "print(f\"{'Baseline + Dropout':<25} {train_acc_dropout:<12.4f} {val_acc_dropout:<12.4f} {test_acc_dropout:<12.4f}\")\n",
    "print(f\"{'Smaller Dense (32)':<25} {train_acc_small:<12.4f} {val_acc_small:<12.4f} {test_acc_small:<12.4f}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff0b32",
   "metadata": {},
   "source": [
    "#### Final Interpretation and Conclusions\n",
    "\n",
    "- Which model performed best overall?\n",
    "- Did dropout help reduce overfitting?\n",
    "- Did reducing capacity help or hurt?\n",
    "- What would you try next?\n",
    "\n",
    "*(Fill this in after running all experiments and comparing results)*\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
